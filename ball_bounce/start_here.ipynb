{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick guide to some WEAVE tools\n",
    "\n",
    "## The problem\n",
    "\n",
    "In this demo we are simulating drop a ball and letting it bounce.\n",
    "\n",
    "We will show how we can take the simulation results and converts them to a sina format for ingestion in other script or in a sina store.\n",
    "\n",
    "## The \"simulation\"\n",
    "\n",
    "We will be using [this scipt](ball_bounce.py) to generate a single simulation of a bouncing ball\n",
    "\n",
    "```bash\n",
    "usage: ball_bounce.py [-h] [--xpos XPOS] [--ypos YPOS] [--zpos ZPOS]\n",
    "                      [--xvel XVEL] [--yvel YVEL] [--zvel ZVEL]\n",
    "                      [--gravity GRAVITY] [--box_side_length BOX_SIDE_LENGTH]\n",
    "                      [--runtime RUNTIME] [--frequency FREQUENCY]\n",
    "                      [--drag DRAG] [--output OUTPUT] [--group GROUP]\n",
    "                      [--run RUN]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  --xpos XPOS, -x XPOS  initial x position (default: 0.0)\n",
    "  --ypos YPOS, -y YPOS  initial y position (default: 0.0)\n",
    "  --zpos ZPOS, -z ZPOS  initial z position (default: 0.0)\n",
    "  --xvel XVEL, -X XVEL  initial x velocity (default: 0.0)\n",
    "  --yvel YVEL, -Y YVEL  initial y velocity (default: 0.0)\n",
    "  --zvel ZVEL, -Z ZVEL  initial z velocity (default: 0.0)\n",
    "  --gravity GRAVITY, -g GRAVITY\n",
    "                        gravity (default: 9.81)\n",
    "  --box_side_length BOX_SIDE_LENGTH, -b BOX_SIDE_LENGTH\n",
    "                        length of the box's sides (default: 10)\n",
    "  --runtime RUNTIME, -r RUNTIME\n",
    "                        length of time we let the simualtion run for (default:\n",
    "                        20)\n",
    "  --frequency FREQUENCY, --ticks_per_seconds FREQUENCY\n",
    "                        sampling rate (default: 20)\n",
    "  --drag DRAG, -d DRAG  drag coefficient (default: 0.1)\n",
    "  --output OUTPUT, -o OUTPUT\n",
    "                        output file (default: None)\n",
    "  --group GROUP, -G GROUP\n",
    "                        group id (default: 1)\n",
    "  --run RUN, -R RUN     run id (default: 1)\n",
    "```\n",
    "\n",
    "\n",
    "This simulation produces a delimeter separated values (`dsv`) file containing the results.\n",
    "\n",
    "## Running many parameters\n",
    "\n",
    "### Basic maestro\n",
    "\n",
    "We can easily run many of this simulations with maestro with [this yaml file](ball_bounce_simple.yaml)\n",
    "\n",
    "```bash\n",
    "maestro run ball_bounce_simple.yaml\n",
    "```\n",
    "\n",
    "### PGEN\n",
    "\n",
    "You can guess if the number of simulation increase it would be very tedious to manually put all these numbers in the yaml file.\n",
    "\n",
    "Fortunately maestro allows for python-generation of the parameters. [This file](pgen.py) will generate 20 random samples for us.\n",
    "\n",
    "## Keeping track of what we ran: Sina\n",
    "\n",
    "As the number of simulation expands it will quickly become hard to figure out what we run\n",
    "\n",
    "Sina can help with this.\n",
    "\n",
    "## Creating sina records from the simulation results\n",
    "\n",
    "The [following script](dsv_to_sina.py) can comb through our generated `dsv` files, and ingest them into a sina catalog.\n",
    "\n",
    "Some LLNL code have Sina built in and produce the `.json` files as they run. You could also run the `sina ingest` command on these files to create the store.\n",
    "\n",
    "In [this maestro yaml file](ball_bounce_suite.yaml) we add an extra step to generate the store after the simulations are ran.\n",
    "\n",
    "Let's run the following command to generate data\n",
    "\n",
    "```bash\n",
    "maestro run -p pgen.py bounce_ball_suite.yaml\n",
    "```\n",
    "\n",
    "### Loading the store\n",
    "\n",
    "Now that we have a store, let's open it up and run some queries on it.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sina\n",
    "\n",
    "store =sina.connect(\"output.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see what is in the store:\n",
    "print(len(list(store.records.find())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's open a record\n",
    "rec = next(store.records.find_with_max(\"num_bounces\", 1))\n",
    "#rec = store.records.get(r_id)\n",
    "print(rec.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Sina\n",
    "\n",
    "In [this notebook](visualization.ipynb) we take a look at some of Sina's query and viz capabilities.\n",
    "\n",
    "\n",
    "## Kosh\n",
    "\n",
    "We have seen how Sina can helps us tracking our simulations and searching through them.\n",
    "\n",
    "Kosh is built on top of Sina and allows the user to access data that are too big to be in the store.\n",
    "\n",
    "In this example we will be working with small files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kosh\n",
    "\n",
    "store = kosh.connect(\"output.sqlite\")  # Similar syntack to Sina\n",
    "\n",
    "# Let's open a record using the id we found in Sina above (record with max of bounces)\n",
    "\n",
    "dataset = store.open(rec[\"id\"])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes on a Kosh dataset are easy to alter and instantly updated in the db by default\n",
    "print(\"N bounces:\",dataset.num_bounces)\n",
    "dataset.my_new_attribute = 6.\n",
    "print(\"New:\", dataset.my_new_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On can also easily acces curves:\n",
    "print(dataset.list_features())\n",
    "dataset[\"time_series/time\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's loop through all the records/dataset in this record group and compute x_vel\n",
    "# and store them in ahdf5 file (outside of db)\n",
    "import h5py\n",
    "for ds in store.find(group_id=dataset.group_id):\n",
    "    x_pos = ds[\"time_series/x_pos\"]\n",
    "    y_pos = ds[\"time_series/y_pos\"]\n",
    "    z_pos = ds[\"time_series/z_pos\"]\n",
    "    time = ds[\"time_series/time\"]\n",
    "    x_vel = (x_pos[1:] - x_pos[:-1])/(time[1:]-time[:-1])\n",
    "    y_vel = (y_pos[1:] - y_pos[:-1])/(time[1:]-time[:-1])\n",
    "    z_vel = (z_pos[1:] - z_pos[:-1])/(time[1:]-time[:-1])\n",
    "    speed = (x_vel+y_vel+z_vel)/3.\n",
    "    nm = f\"vel_{ds.id}.hdf5\"\n",
    "    h5 = h5py.File(nm,\"w\")\n",
    "    h5[\"x_vel\"] = x_vel\n",
    "    h5[\"y_vel\"] = y_vel\n",
    "    h5[\"z_vel\"] = z_vel\n",
    "    h5[\"speed\"] = speed\n",
    "    h5.close()\n",
    "    # Associate this new external data to dataset\n",
    "    ds.associate(nm, \"hdf5\")\n",
    "\n",
    "print(ds)\n",
    "print(ds.list_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can access both curves or external data in the same way:\n",
    "print(dataset[\"time_series/x_pos\"][:5])\n",
    "print(dataset[\"x_vel\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kosh also offer the notion of ensembles which is based on Sina' relationships\n",
    "my_group = store.create_ensemble()\n",
    "# attributes of a group are shared by all memebers\n",
    "my_group.a_group_attribute = \"foo\"\n",
    "\n",
    "# Let's add our group members to this ensemble:\n",
    "for ds in store.find(group_id=dataset.group_id):\n",
    "    my_group.add(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.a_group_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could search the ensemble\n",
    "dss = list(my_group.find_datasets(num_bounces=sina.utils.DataRange(min=21)))\n",
    "print(len(dss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's compute the average speed for this ensemble\n",
    "# for this we will use an operator\n",
    "@kosh.numpy_operator\n",
    "def Avg(*inputs):\n",
    "    avg = inputs[0][:]\n",
    "    for input_ in inputs[1:]:\n",
    "        avg += input_[:]\n",
    "    return avg/len(inputs)\n",
    "\n",
    "\n",
    "avg_speed = Avg(*( _[\"speed\"] for _ in my_group.find_datasets()))[:]\n",
    "print(avg_speed[:5])\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now store that result in a file and associate that file with the group\n",
    "import numpy\n",
    "nm = f\"avg_speed_{my_group.id}.hdf5\"\n",
    "h5 = h5py.File(nm, \"w\")\n",
    "h5[\"avg_speed\"]= avg_speed\n",
    "h5.close()\n",
    "\n",
    "my_group.associate(nm, \"hdf5\")\n",
    "my_group.group_speed = float(numpy.average(avg_speed))\n",
    "print(my_group)\n",
    "print(ds.group_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_group[\"avg_speed\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kosh Environment",
   "language": "python",
   "name": "kosh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
