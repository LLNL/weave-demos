{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numbers import Number\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import kosh\n",
    "import math\n",
    "import statistics\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "# Initialization\n",
    "database = './data/num_res_output.sqlite'\n",
    "target_type = \"csv_rec\"\n",
    "datastore = kosh.connect(database)\n",
    "print(\"Kosh is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Data to Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def RMSE(x_true, x_pred):\n",
    "    summation = 0\n",
    "    for xt, xp in zip(x_true, x_pred):\n",
    "        summation += (xt-xp)**2\n",
    "    mean = summation/len(x_true)\n",
    "    rmse = math.sqrt(mean)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def diff(x_true, x_pred):\n",
    "    dif = []\n",
    "    for xt, xp in zip(x_true, x_pred):\n",
    "        dif.append(xt-xp)\n",
    "    return dif\n",
    "\n",
    "\n",
    "###################################################\n",
    "# Finding common timesteps using largest timestep #\n",
    "###################################################\n",
    "\n",
    "val_largest_time_step = list(datastore.find(id_pool = '47bcda_3_15'))[0]\n",
    "time_largest_time_step = val_largest_time_step['physics_cycle_series/time']\n",
    "\n",
    "val_nominal_time_step = list(datastore.find(id_pool = '47bcda_3_20'))[0]\n",
    "time_nominal_time_step = val_nominal_time_step['physics_cycle_series/time']\n",
    "\n",
    "val_smallest_time_step = list(datastore.find(id_pool = '47bcda_3_25'))[0]\n",
    "time_smallest_time_step = val_smallest_time_step['physics_cycle_series/time']\n",
    "\n",
    "time_in_all = list(set.intersection(*map(set, [time_largest_time_step, time_nominal_time_step, time_smallest_time_step])))\n",
    "\n",
    "for dataset in datastore.find(): # Each record is now a dataset\n",
    "\n",
    "    x_pred = dataset['physics_cycle_series/x_pos'][:]\n",
    "    y_pred = dataset['physics_cycle_series/y_pos'][:]\n",
    "    z_pred = dataset['physics_cycle_series/z_pos'][:]\n",
    "    time = dataset['physics_cycle_series/time'][:]\n",
    "\n",
    "\n",
    "    x_pred_common = []\n",
    "    y_pred_common = []\n",
    "    z_pred_common = []\n",
    "    time_common = []\n",
    "\n",
    "    for i, t in enumerate(time):\n",
    "        for t2 in time_in_all:\n",
    "            if t == t2:\n",
    "                x_pred_common.append(x_pred[i])\n",
    "                y_pred_common.append(y_pred[i])\n",
    "                z_pred_common.append(z_pred[i])\n",
    "                time_common.append(time[i])\n",
    "\n",
    "#     dataset.add_curve(time_common,'time_common', 'common_data')\n",
    "#     dataset.add_curve(x_common,'x_common', 'common_data')\n",
    "#     dataset.add_curve(y_common,'y_common', 'common_data')\n",
    "#     dataset.add_curve(z_common,'z_common', 'common_data')\n",
    "\n",
    "###############################################################\n",
    "# Comparing to TICKS_PER_SECOND = 20 with new common timestep #\n",
    "###############################################################\n",
    "\n",
    "val = list(datastore.find(id_pool = '47bcda_3_20'))[0]\n",
    "\n",
    "# Printing Attributes and Features\n",
    "print('Attributes:')\n",
    "print('\\t',val.list_attributes())\n",
    "print('\\n')\n",
    "print('Features Sets:')\n",
    "print('\\t',val.list_features())\n",
    "            \n",
    "x_true = val['common_data/x_common'][:]\n",
    "y_true = val['common_data/y_common'][:]\n",
    "z_true = val['common_data/z_common'][:]\n",
    "time_true = val['common_data/time_common'][:]\n",
    "\n",
    "for dataset in datastore.find(): # Each record is now a dataset\n",
    "    print(f\"id: {dataset.id}\")\n",
    "    x_pred = dataset['common_data/x_common'][:]\n",
    "    y_pred = dataset['common_data/y_common'][:]\n",
    "    z_pred = dataset['common_data/z_common'][:]\n",
    "\n",
    "    x_diff = diff(x_true, x_pred)\n",
    "    x_rmse = RMSE(x_true, x_pred)\n",
    "    y_diff = diff(y_true, y_pred)\n",
    "    y_rmse = RMSE(y_true, y_pred)\n",
    "    z_diff = diff(z_true, z_pred)\n",
    "    z_rmse = RMSE(z_true, z_pred)\n",
    "\n",
    "    print(f\"\\tx_rmse: {x_rmse}\")\n",
    "    print(f\"\\ty_rmse: {y_rmse}\")\n",
    "    print(f\"\\tz_rmse: {z_rmse}\")\n",
    "\n",
    "    setattr(dataset, 'x_rmse', x_rmse)\n",
    "#     dataset.add_curve(x_diff,'x_diff', 'common_data')\n",
    "    setattr(dataset, 'y_rmse', y_rmse)\n",
    "#     dataset.add_curve(y_diff,'y_diff', 'common_data')\n",
    "    setattr(dataset, 'z_rmse', z_rmse)\n",
    "#     dataset.add_curve(z_diff,'z_diff', 'common_data')\n",
    "\n",
    "\n",
    "########################################################\n",
    "# Mean and Standard Deviation with new common timestep #\n",
    "########################################################\n",
    "\n",
    "mean_rec = Record(id=\"mean\", type=\"summary\")\n",
    "# recs.delete(\"mean\")\n",
    "\n",
    "x_temp = []\n",
    "y_temp = []\n",
    "z_temp = []\n",
    "\n",
    "x_mean = []\n",
    "y_mean = []\n",
    "z_mean = []\n",
    "x_std = []\n",
    "y_std = []\n",
    "z_std = []\n",
    "\n",
    "for i, t in enumerate(time_common):\n",
    "\n",
    "    for dataset in datastore.find(): # Each record is now a dataset\n",
    "        x_pred = dataset['common_data/x_common'][i]\n",
    "        y_pred = dataset['common_data/y_common'][i]\n",
    "        z_pred = dataset['common_data/z_common'][i]\n",
    "\n",
    "        x_temp.append(x_pred)\n",
    "        y_temp.append(y_pred)\n",
    "        z_temp.append(z_pred)\n",
    "\n",
    "    x_mean.append(statistics.mean(x_temp))\n",
    "    y_mean.append(statistics.mean(y_temp))\n",
    "    z_mean.append(statistics.mean(z_temp))\n",
    "    x_std.append(statistics.stdev(x_temp))\n",
    "    y_std.append(statistics.stdev(y_temp))\n",
    "    z_std.append(statistics.stdev(z_temp))\n",
    "\n",
    "    x_temp = []\n",
    "    y_temp = []\n",
    "    z_temp = []\n",
    "\n",
    "mean_set = mean_rec.add_curve_set(\"mean_data\")\n",
    "mean_set.add_curve(time_common, 'time_common', \"mean_data\")\n",
    "mean_set.add_curve(x_mean, 'x_pos_mean', \"mean_data\")\n",
    "mean_set.add_curve(y_mean, 'y_pos_mean', \"mean_data\")\n",
    "mean_set.add_curve(z_mean, 'z_pos_mean', \"mean_data\")\n",
    "mean_set.add_curve(x_std, 'x_pos_std', \"mean_data\")\n",
    "mean_set.add_curve(y_std, 'y_pos_std', \"mean_data\")\n",
    "mean_set.add_curve(z_std, 'z_pos_std', \"mean_data\")\n",
    "\n",
    "mean_set.add_curve([x_mean[i] + x_std[i] for i in range(len(time_common))], 'x_pos_mean_plus_std', \"mean_data\")\n",
    "mean_set.add_curve([y_mean[i] + y_std[i] for i in range(len(time_common))], 'y_pos_mean_plus_std', \"mean_data\")\n",
    "mean_set.add_curve([z_mean[i] + z_std[i] for i in range(len(time_common))], 'z_pos_mean_plus_std', \"mean_data\")\n",
    "mean_set.add_curve([x_mean[i] - x_std[i] for i in range(len(time_common))], 'x_pos_mean_minus_std', \"mean_data\")\n",
    "mean_set.add_curve([y_mean[i] - y_std[i] for i in range(len(time_common))], 'y_pos_mean_minus_std', \"mean_data\")\n",
    "mean_set.add_curve([z_mean[i] - z_std[i] for i in range(len(time_common))], 'z_pos_mean_minus_std', \"mean_data\")\n",
    "\n",
    "mean_set.add_curve([x_mean[i] + 2*x_std[i] for i in range(len(time_common))], 'x_pos_mean_plus_2std', \"mean_data\")\n",
    "mean_set.add_curve([y_mean[i] + 2*y_std[i] for i in range(len(time_common))], 'y_pos_mean_plus_2std', \"mean_data\")\n",
    "mean_set.add_curve([z_mean[i] + 2*z_std[i] for i in range(len(time_common))], 'z_pos_mean_plus_2std', \"mean_data\")\n",
    "mean_set.add_curve([x_mean[i] - 2*x_std[i] for i in range(len(time_common))], 'x_pos_mean_minus_2std', \"mean_data\")\n",
    "mean_set.add_curve([y_mean[i] - 2*y_std[i] for i in range(len(time_common))], 'y_pos_mean_minus_2std', \"mean_data\")\n",
    "mean_set.add_curve([z_mean[i] - 2*z_std[i] for i in range(len(time_common))], 'z_pos_mean_minus_2std', \"mean_data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 1\n",
    "\n",
    "id_pool = list(datastore.find(ids_only=True))\n",
    "id_pool.remove('mean')\n",
    "id_pool = id_pool[::-1]\n",
    "print(id_pool)\n",
    "\n",
    "for dataset_id in id_pool:\n",
    "\n",
    "    dataset = list(datastore.find(id_pool=dataset_id))[0]\n",
    "\n",
    "    if header == 1:\n",
    "        print('| dataset.id | x_pos_initial | y_pos_initial | z_pos_initial | x_vel_initial | y_vel_initial | z_vel_initial |')\n",
    "        print('| --- | --- | --- | --- | --- | --- | --- |')\n",
    "        header = 0\n",
    "    print('|', dataset.id,\n",
    "          '|', dataset.x_pos_initial,\n",
    "          '|', dataset.y_pos_initial,\n",
    "          '|', dataset.z_pos_initial,\n",
    "          '|', dataset.x_vel_initial,\n",
    "          '|', dataset.y_vel_initial,\n",
    "          '|', dataset.z_vel_initial,\n",
    "          '|'\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting QoIs and their Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
    "\n",
    "for dataset in datastore.find(): # Each record is now a dataset\n",
    "    ax[0, 0].plot(dataset['common_data/time_common'][:], dataset['common_data/x_common'][:], label=dataset.id)\n",
    "    ax[0, 1].plot(dataset['common_data/time_common'][:], dataset['common_data/y_common'][:], label=dataset.id)\n",
    "    ax[0, 2].plot(dataset['common_data/time_common'][:], dataset['common_data/z_common'][:], label=dataset.id)\n",
    "    \n",
    "    \n",
    "_ = vis.create_line_plot(fig=fig, ax=ax[0, 0], x=\"time_common\", y=\"x_common\", title=\"{y_name}\", id_pool=id_pool)\n",
    "_ = vis.create_line_plot(fig=fig, ax=ax[0, 1], x=\"time_common\", y=\"y_common\", title=\"{y_name}\", id_pool=id_pool)\n",
    "_ = vis.create_line_plot(fig=fig, ax=ax[0, 2], x=\"time_common\", y=\"z_common\", title=\"{y_name}\", id_pool=id_pool)\n",
    "\n",
    "_ = vis.create_line_plot(fig=fig, ax=ax[1, 0], x=\"time_common\", y=\"x_diff\", title=\"{y_name}\", id_pool=id_pool)\n",
    "_ = vis.create_line_plot(fig=fig, ax=ax[1, 1], x=\"time_common\", y=\"y_diff\", title=\"{y_name}\", id_pool=id_pool)\n",
    "_ = vis.create_line_plot(fig=fig, ax=ax[1, 2], x=\"time_common\", y=\"z_diff\", title=\"{y_name}\", id_pool=id_pool)\n",
    "\n",
    "fig.savefig(\"./images/QoIs_num_res.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean = recs.get('mean')\n",
    "\n",
    "mean_set = mean.get_curve_set(\"mean_data\")\n",
    "time = mean_set.get_independent('time_common')['value']\n",
    "x_pos_mean_plus_2std = mean_set.get_dependent('x_pos_mean_plus_2std')['value']\n",
    "y_pos_mean_plus_2std = mean_set.get_dependent('y_pos_mean_plus_2std')['value']\n",
    "z_pos_mean_plus_2std = mean_set.get_dependent('z_pos_mean_plus_2std')['value']\n",
    "\n",
    "x_pos_mean_minus_2std = mean_set.get_dependent('x_pos_mean_minus_2std')['value']\n",
    "y_pos_mean_minus_2std = mean_set.get_dependent('y_pos_mean_minus_2std')['value']\n",
    "z_pos_mean_minus_2std = mean_set.get_dependent('z_pos_mean_minus_2std')['value']\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "_ = vis.create_line_plot(fig=fig, ax=ax[0], x=\"time_common\", y=\"x_pos_mean\", title=\"{y_name}\", id_pool=['mean'])\n",
    "_ = vis.create_line_plot(fig=fig, ax=ax[1], x=\"time_common\", y=\"y_pos_mean\", title=\"{y_name}\", id_pool=['mean'])\n",
    "_ = vis.create_line_plot(fig=fig, ax=ax[2], x=\"time_common\", y=\"z_pos_mean\", title=\"{y_name}\", id_pool=['mean'])\n",
    "\n",
    "ax[0].fill_between(time, x_pos_mean_plus_2std, x_pos_mean_minus_2std, alpha=0.25)\n",
    "ax[1].fill_between(time, y_pos_mean_plus_2std, y_pos_mean_minus_2std, alpha=0.25)\n",
    "ax[2].fill_between(time, z_pos_mean_plus_2std, z_pos_mean_minus_2std, alpha=0.25)\n",
    "\n",
    "ax[0].legend(labels=['Simulation Mean', '$\\mu \\pm 2 \\sigma$'])\n",
    "ax[1].legend(labels=['Simulation Mean', '$\\mu \\pm 2 \\sigma$'])\n",
    "ax[2].legend(labels=['Simulation Mean', '$\\mu \\pm 2 \\sigma$'])\n",
    "fig.savefig(\"./images/QoIs_u_num.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ball-bounce-demo",
   "language": "python",
   "name": "ball-bounce-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
