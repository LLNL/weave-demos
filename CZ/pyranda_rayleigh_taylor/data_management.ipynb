{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2843b65e-c334-4859-86f4-022dfd54775b",
   "metadata": {},
   "source": [
    "# Data Management with Kosh\n",
    "\n",
    "After generating data with Maestro or Merlin we need to access the data in our Kosh/Sina store. After some data manipulation we can train a surrogate model to emulate the Pyranda physics calculations.\n",
    "\n",
    "The Kosh store gives us the convenience of saving all the variables and outputs with the associated metadata. Instead of saving varibales like the Atwood number and velocity-magnitude in the filenames we can save all the information we need in the metadata. Then it's convenient to find in our ensemble later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f47f86-53f8-4482-82d1-bbaa3e63a9c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3039274023.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [5]\u001b[0;36m\u001b[0m\n\u001b[0;31m    except:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import kosh\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler as MMS\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Connect to the Kosh store\n",
    "store_dir = os.path.join(os.getcwd(), \"Experiments/pyranda.sql\")\n",
    "store = kosh.connect(store_dir)\n",
    "\n",
    "# Create an ensemble or use an existing one\n",
    "# We can associate all our datasets and images with this ensemble\n",
    "try:\n",
    "    ensemble = next(store.find_ensembles(name=basename_dirname_workspace)\n",
    "except:\n",
    "    ensemble = store.create_ensemble(name=basename_dirname_workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd243c76-b55a-4594-b7dd-6b647ae218fc",
   "metadata": {},
   "source": [
    "## Choosing times to evaluate mixing width\n",
    "\n",
    "We gathered a lot of data with the simulation runs. However, we need to choose specific points in time to evaluate mixing width. Here we can choose the number of time points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567ae25-3d2a-452b-ab28-3ec6ab8adb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose number of times here\n",
    "NTpts = 1\n",
    "# All simulations run from 0.0 to at least 60.0 seconds\n",
    "Tmin = 0.0\n",
    "Tmax = 60.0\n",
    "\n",
    "# The time points are evenly space between 0.0 and 60.0\n",
    "samples = []\n",
    "sample_times = np.linspace(Tmin, Tmax, NTpts)\n",
    "# If we only want one point we will evaluate at the max time\n",
    "if len(sample_times) == 1:\n",
    "    sample_times = [Tmax]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467dcc0e-417e-415e-921a-5626c137ead2",
   "metadata": {},
   "source": [
    "## Gathering variables from each simulation run\n",
    "\n",
    "We can loop through the datasets in our Kosh store, and save the inputs and outputs of interest. Data of all different types can be associated together in our ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015ab47-97a6-4d52-87c7-f82419833887",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_cases = len(list(store.find(types=\"pyranda\", run_type=run_type, ids_only=True)))\n",
    "for i, case in enumerate(store.find(types=\"pyranda\", run_type=run_type), start=1):\n",
    "    # Let's add this dataset to our ensemble\n",
    "    print(\"*********************************\")\n",
    "    print(\"DS:\", case.id)\n",
    "    print(\"*********************************\")\n",
    "    ensemble.add(case)\n",
    "\n",
    "    # Let's retrieve the variables of interest\n",
    "    time = case[\"variables/time\"][:] # Time\n",
    "    width = case[\"variables/mixing width\"][:] # Width\n",
    "    mixed = case[\"variables/mixedness\"][:] # Mixedness\n",
    "    atwood = case.atwood_number\n",
    "    velocity = case.velocity_magnitude\n",
    "    lbl = f\"Vel: {velocity} - At: {atwood}\"\n",
    "    plt.figure(2)\n",
    "    plt.plot(time, width, -o, label=lbl)\n",
    "    for st in sample_times:\n",
    "        plt.axvline(x=st, color='b', label=f\"{st} s\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Mix Width\")\n",
    "    plt.title(\"Rayleigh-Taylor Simulations\")\n",
    "    if i == N_cases:\n",
    "        fnm = \"all_mixing_width.png\"\n",
    "        ensemble.associate(fnm, \"png\", metadata={\"title\": lbl})\n",
    "\n",
    "    # Plotting to show the input sampling design\n",
    "    plt.figure(1)\n",
    "    plt.plot(atwood, velocity, 'ko')\n",
    "    plt.xlabel(\"Atwood number\")\n",
    "    plt.ylabel(\"Velocity magnitude\")\n",
    "    plt.title(\"Latin Hypercube Space-Filling Design\")\n",
    "    if i == N_cases:\n",
    "        fnm = \"atwood_vs_vel.png\"\n",
    "        ensemble.associate(fnm, \"png\", metadata={\"title\":'atwood vs velocity'})\n",
    "            \n",
    "        # For each time, qoi, get NTpts\n",
    "        #  Sample = [atwood, velocity, w(0), w(1), w(2) ...]\n",
    "        sample_widths = np.interp(sample_times, time, width)\n",
    "        sample = np.insert( sample_widths, 0, atwood)\n",
    "        sample = np.insert( sample, 1, velocity)\n",
    "        samples.append( sample )\n",
    "samples = np.array(samples)\n",
    "\n",
    "print(f\"Data size: {samples.shape})\n",
    "print(\"First 5 rows\")\n",
    "print(samples[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d8510f-56c5-4acf-b81f-20ee4360c6a8",
   "metadata": {},
   "source": [
    "## Fitting the Gaussian Process (GP) Models\n",
    "\n",
    "We will fit a Gaussian process surrogate model for each time we chose from the simulation. This model will need to be able to predict mixing width very quickly and accurately. The Gaussian process model can return a prediction and a standard error estimate. The error should be very small for data points it was trained on, and larger when it has to interpolate between training data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184617d-4c8a-4774-9274-9b18341f0f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need an array of model inputs for the GP\n",
    "xgp = samples[:,0:2]\n",
    "# The GP model performs better when the inputs are scaled\n",
    "scaler = MMS()\n",
    "scaled_samples = scaler.fit_transform(xgp)\n",
    "\n",
    "# Get inputs for 2D plots\n",
    "# We're going to evaluate the model at points it was not trained on\n",
    "atwoods    = np.linspace(.25,.75, 100)\n",
    "velocities = np.linspace(.75, 1.25, 100)\n",
    "at2d, vel2d = np.meshgrid(atwoods, velocities)\n",
    "atwoods = at2d.flatten().reshape(-1,1)\n",
    "velocities = vel2d.flatten().reshape(-1,1)\n",
    "inputs = np.concatenate( (atwoods, velocities), axis=1 )\n",
    "scaled_inputs = scaler.transform(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c356c9d-2c4d-4987-a077-c789db5d982a",
   "metadata": {},
   "source": [
    "## Plotting the GP Predictions\n",
    "\n",
    "Here we're going to evaluate the model at many inputs to see how well it can predict mixing width. The mix width prediction is shown as a blue response surface over the Atwood and velocity values. At the base of the plot you can see the standard error of the prediction. The error is very low in the areas where the model was trained, but we forced to model to predict outside of the range it was trained on and you can see the error increases at the edges where it did not have traning data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9580ee0f-5990-45c3-bf28-dba0dd5fadf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GP_times = []\n",
    "# Fitting a GP model for NTpts in time\n",
    "for ii in range(NTpts):\n",
    "    sample_time = sample_times[ii]\n",
    "    y = samples[:, 2 + ii]  # Get width at this time-slice\n",
    "    GP_times.append(GPR().fit(scaled_samples, y))\n",
    "\n",
    "    # See GP prediction in 2D\n",
    "    pred, std = GP_times[ii].predict(scaled_inputs, return_std=True)\n",
    "\n",
    "    fig_num = 3 + ii\n",
    "    fig = plt.figure(fig_num)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    pred2d = pred.reshape(at2d.shape)\n",
    "    std2d = std.reshape(at2d.shape)\n",
    "    ax.plot_surface(at2d, vel2d, pred2d)\n",
    "    ax.contourf(at2d, vel2d, std2d, zdir='z', offset=0, cmap='coolwarm')\n",
    "    ax.set_xlabel('Atwood')\n",
    "    ax.set_ylabel('Velocity')\n",
    "    ax.set_zlabel('Width')\n",
    "    fnm = f\"GP_at_{sample_time}_s.png\"\n",
    "    ensemble.associate(fnm, \"png\", metadata={\"title\":'2D GP'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdb8a4d-804d-4ebd-b818-7120f86ce04b",
   "metadata": {},
   "source": [
    "## Validation with Leave-One-Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7f8af5-35e0-4eda-814a-f9f3541745a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "\n",
    "outputs = samples[:, 2:]\n",
    "\n",
    "time_point_error = []\n",
    "for ii in range(NTpts):\n",
    "    loo_pred = []\n",
    "    loo_std = []\n",
    "    loo_sqerror = []\n",
    "    for i, (train_index, test_index) in enumerate(loo.split(scaled_samples)):\n",
    "        y = outputs[:, ii]\n",
    "        gp_model = GPR().fit(scaled_samples[train_index, :])\n",
    "        pred, std = gp_model.predict(scaled_samples[test_index, :], return_std=True)\n",
    "        loo_pred.append(pred)\n",
    "        loo_std.append(std)\n",
    "        loo_sqerror.append((y[test_index, :] - pred)**2)\n",
    "    plt.figure(3 + NTpts + ii)\n",
    "    plt.errorbar(outputs[:, ii], loo_pred, yerr=loo_std, 'b')\n",
    "    plt.xlabel(\"Actual Mix Width\")\n",
    "    plt.ylabel(\"Predicted Mix Width\")\n",
    "    plt.title(f\"GP Model at {sample_times[ii]} s\")\n",
    "    print(f\"MSE at {sample_times[ii]} s: {sum(loo_sqerror)/len(loo_sqerror)}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_tik_env",
   "language": "python",
   "name": "weave_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
